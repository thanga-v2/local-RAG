{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d6e693b-5ff1-460a-98b3-3f66ce788150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aac39bf5-7aa6-4f41-8ca3-f907cca4086d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = np.array([[1,2,3],[2,3,4],[9,0,1]])\n",
    "vec2 = np.array([[1,4,5],[2,3,4],[9,0,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2f6074-76b7-497b-b1c6-49f31034e909",
   "metadata": {},
   "source": [
    "### it has two dimensions - rows and columns\n",
    "### hence 2-D vectors (we can access using row indices and coloumn indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15ddebaa-6835-42ec-b180-6dd3b5e99ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1eaa964e-384e-43e6-821f-f13a42040838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec2.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bad05bff-ea7a-4de6-9a5c-9bae0c89c126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [2, 3, 4],\n",
       "       [9, 0, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e19ee1d7-43e0-4894-9ade-4aa06de7962f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4, 5],\n",
       "       [2, 3, 4],\n",
       "       [9, 0, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1d61c9-6e01-46a7-8671-66fd33513555",
   "metadata": {},
   "source": [
    "# dot product using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "831dcb4f-db58-4b0a-aef9-2e9755959c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32, 10, 16],\n",
       "       [44, 17, 26],\n",
       "       [18, 36, 46]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dot product\n",
    "\n",
    "np.dot(vec1,vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cd288f-1be4-4d57-a60e-6a578f0e7034",
   "metadata": {},
   "source": [
    "# dot product using torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b37f2bee-40d1-4e1f-a4e7-b31647005b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1673bebc-4106-43ac-9627-b68abcb67cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [2 3 4]\n",
      " [9 0 1]]\n",
      "tensor([[1, 2, 3],\n",
      "        [2, 3, 4],\n",
      "        [9, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "vec1_tensor = torch.tensor(vec1)\n",
    "print(vec1)\n",
    "print(vec1_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91f0c89d-98b5-4132-8653-c7976b19ad41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4 5]\n",
      " [2 3 4]\n",
      " [9 0 1]]\n",
      "tensor([[1, 4, 5],\n",
      "        [2, 3, 4],\n",
      "        [9, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "vec2_tensor = torch.tensor(vec2)\n",
    "print(vec2)\n",
    "print(vec2_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d9b9a0a-467a-4b87-bd9d-c94753cca63c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "1D tensors expected, but got 2D and 2D tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dot_product_torch \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvec1_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvec2_tensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 1D tensors expected, but got 2D and 2D tensors"
     ]
    }
   ],
   "source": [
    "dot_product_torch = torch.dot(vec1_tensor,vec2_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00718014-bc24-41d3-b916-9ec7f81fbb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c12675-c26d-4943-ada9-0b39bdaac15a",
   "metadata": {},
   "source": [
    "# torch.dot function expects 1-D vectors\n",
    "\n",
    "Our vector is 2-D,\n",
    "\n",
    "we can use `torch.squeeze` to remove any extra dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b6d1a32-55ba-48ba-8aa5-d4c4f10d73da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [2, 3, 4],\n",
      "        [9, 0, 1]])\n",
      "shape:torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "vec1_tensor = torch.squeeze(vec1_tensor)\n",
    "print(vec1_tensor)\n",
    "print(f'shape:{vec1_tensor.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9486ac8-b943-4818-9bab-119f5d669ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4, 5],\n",
      "        [2, 3, 4],\n",
      "        [9, 0, 1]])\n",
      "shape:torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "vec2_tensor = torch.squeeze(vec2_tensor)\n",
    "print(vec2_tensor)\n",
    "print(f'shape:{vec2_tensor.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b9160ce-9a3e-4e6b-b7bc-ae05c8922194",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "1D tensors expected, but got 2D and 2D tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvec1_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvec2_tensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 1D tensors expected, but got 2D and 2D tensors"
     ]
    }
   ],
   "source": [
    "torch.dot(vec1_tensor,vec2_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4609ddd-a956-4382-a4c4-eb0889d86a78",
   "metadata": {},
   "source": [
    "### It won't be resolved, because, our input matrix is itself 2-D\n",
    "\n",
    "### Try matric multiplication for dot_product for 2-D\n",
    "\n",
    "`torch.matmul()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e6bc92c-53ae-4112-979c-082f37d0edf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24, 20, 12],\n",
       "        [34, 29, 22],\n",
       "        [14, 22, 82]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_dot_product = torch.matmul(vec1_tensor,vec2_tensor.T) # Transpose vec2_tensor to match dimensions\n",
    "torch_dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4752af52-db33-44ad-8117-673616f23aef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b19bae1-0997-47ce-bc2c-23531a326a4f",
   "metadata": {},
   "source": [
    "# dot product using sentence_transformers.util.dot_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3126996-bc10-4b30-8a41-c0b1502d4911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5abfae24-f55c-476e-9430-3469d2913f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model first\n",
    "\n",
    "model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe111e6c-cb94-4e1c-90f1-9b1762d665cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.int64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# get embeddings\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m embedding_1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvec1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:340\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    339\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 340\u001b[0m length_sorted_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort([\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text_length(sen) \u001b[38;5;28;01mfor\u001b[39;00m sen \u001b[38;5;129;01min\u001b[39;00m sentences])\n\u001b[1;32m    341\u001b[0m sentences_sorted \u001b[38;5;241m=\u001b[39m [sentences[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m length_sorted_idx]\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start_index \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sentences), batch_size, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatches\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:340\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    339\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 340\u001b[0m length_sorted_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort([\u001b[38;5;241m-\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_text_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43msen\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m sen \u001b[38;5;129;01min\u001b[39;00m sentences])\n\u001b[1;32m    341\u001b[0m sentences_sorted \u001b[38;5;241m=\u001b[39m [sentences[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m length_sorted_idx]\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start_index \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sentences), batch_size, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatches\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:792\u001b[0m, in \u001b[0;36mSentenceTransformer._text_length\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text)\n\u001b[1;32m    791\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 792\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m([\u001b[38;5;28mlen\u001b[39m(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m text])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:792\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text)\n\u001b[1;32m    791\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 792\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m([\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m text])\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.int64' has no len()"
     ]
    }
   ],
   "source": [
    "# get embeddings\n",
    "embedding_1 = model.encode(vec1, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ede082-637d-4c56-b5e3-4994c18687e5",
   "metadata": {},
   "source": [
    "# we cannot pass arrays\n",
    "# we need to convert into strings / list of strings\n",
    "# and then pass it into encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ac841d29-b8e3-46de-8841-7f8ea4459e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [2, 3, 4], [9, 0, 1]]\n",
      "[[1, 4, 5], [2, 3, 4], [9, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "vec1_to_list = vec1.tolist()\n",
    "print(vec1_to_list)\n",
    "vec2_to_list = vec2.tolist()\n",
    "print(vec2_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4cec5fed-2606-4a00-b1cb-469288781b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data : [[ 0.05442027  0.03953015  0.00451795 ...  0.01809237 -0.09158307\n",
      "  -0.0610432 ]\n",
      " [ 0.05589646 -0.02311823  0.00352699 ...  0.01853339 -0.10076108\n",
      "  -0.03419292]\n",
      " [-0.05076252 -0.02119459  0.00390377 ...  0.01688002 -0.03411417\n",
      "  -0.00084902]]\n",
      "shape : (3, 768)\n"
     ]
    }
   ],
   "source": [
    "embedding1 = model.encode(vec1_to_list)\n",
    "print(f'data : {embedding1}')\n",
    "print(f'shape : {embedding1.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0fc4bcc3-8932-4a2f-9d64-3c0efcf0f749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data : tensor([[ 0.0544,  0.0395,  0.0045,  ...,  0.0181, -0.0916, -0.0610],\n",
      "        [ 0.0559, -0.0231,  0.0035,  ...,  0.0185, -0.1008, -0.0342],\n",
      "        [-0.0508, -0.0212,  0.0039,  ...,  0.0169, -0.0341, -0.0008]],\n",
      "       device='mps:0')\n",
      "shape : torch.Size([3, 768])\n"
     ]
    }
   ],
   "source": [
    "device = 'mps'\n",
    "embedding1 = model.encode(vec1_to_list, convert_to_tensor=True).to(device)\n",
    "print(f'data : {embedding1}')\n",
    "print(f'shape : {embedding1.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "caebf940-e8cd-4d40-a376-0be1a9bf66c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data : [[-0.02232088 -0.00593381 -0.01298535 ...  0.033519   -0.05398313\n",
      "  -0.05386225]\n",
      " [ 0.05589646 -0.02311823  0.00352699 ...  0.01853339 -0.10076108\n",
      "  -0.03419292]\n",
      " [-0.05076252 -0.02119459  0.00390377 ...  0.01688002 -0.03411417\n",
      "  -0.00084902]]\n",
      "shape : (3, 768)\n"
     ]
    }
   ],
   "source": [
    "embedding2 = model.encode(vec2_to_list)\n",
    "print(f'data : {embedding2}')\n",
    "print(f'shape : {embedding2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "acb6f9c7-9ade-4e2e-a421-8c465bfa4c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data : tensor([[-0.0223, -0.0059, -0.0130,  ...,  0.0335, -0.0540, -0.0539],\n",
      "        [ 0.0559, -0.0231,  0.0035,  ...,  0.0185, -0.1008, -0.0342],\n",
      "        [-0.0508, -0.0212,  0.0039,  ...,  0.0169, -0.0341, -0.0008]],\n",
      "       device='mps:0')\n",
      "shape : torch.Size([3, 768])\n"
     ]
    }
   ],
   "source": [
    "embedding2 = model.encode(vec2_to_list,convert_to_tensor=True).to(device)\n",
    "print(f'data : {embedding2}')\n",
    "print(f'shape : {embedding2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "623a9e8a-e878-443e-ab2b-cf497f1776a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7276, 0.8158, 0.4960],\n",
       "        [0.7961, 1.0000, 0.5855],\n",
       "        [0.6312, 0.5855, 1.0000]], device='mps:0')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product = util.dot_score(a=embedding1, b=embedding2)\n",
    "dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ffca8246-4225-4a6b-a9d4-b6fa15c3cb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[0.8158, 0.7276, 0.4960],\n",
       "        [1.0000, 0.7961, 0.5855],\n",
       "        [1.0000, 0.6312, 0.5855]], device='mps:0'),\n",
       "indices=tensor([[1, 0, 2],\n",
       "        [1, 0, 2],\n",
       "        [2, 0, 1]], device='mps:0'))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(dot_product, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "14fcd4c3-d136-40cf-a04c-f5f31fdb7832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1_to_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6f02a220-5a36-4392-96d4-8030aa8a4a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec2_to_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9d50ac32-0dd0-4684-8f97-8c22bfaeda8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1_to_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0d4de8a9-eac1-482f-9c92-ce038f6533df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 5]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec2_to_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e1cd1e12-38ec-416d-b9e0-f34db324d8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [2, 3, 4],\n",
       "        [9, 0, 1]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b91e36-17b7-49c1-b294-59f12ff086cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c02412b6-38e2-498e-9efe-61f8e26e1283",
   "metadata": {},
   "source": [
    "# Cosine similarity\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "36f9da7e-5624-40a6-b23f-fd4dfc1173be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def dot_product(vector1,vector2):\n",
    "    return torch.dot(vector1,vector2)\n",
    "\n",
    "\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    dot_product = torch.dot(vector1,vector2)\n",
    "\n",
    "\n",
    "    # Euclidean / L2 norm\n",
    "    norm_vector1 = torch.sqrt(torch.sum(vector1**2))\n",
    "    norm_vector2 = torch.sqrt(torch.sum(vector2**2))\n",
    "\n",
    "    return dot_product / (norm_vector1 * norm_vector2)\n",
    "\n",
    "\n",
    "# dot_product(torch.tensor(8,dtype=float32),torch.tensor(9,dtype=torch.float32))\n",
    "# Example vectors / tensors\n",
    "\n",
    "vector1 = torch.tensor([1,2,3], dtype=torch.float32)\n",
    "vector2 = torch.tensor([1,2,3], dtype=torch.float32)\n",
    "vector3 = torch.tensor([4,5,6], dtype=torch.float32)\n",
    "vector4 = torch.tensor([-1,-5,-6], dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda1828c-095d-49b9-ae82-1c1caeb29b5f",
   "metadata": {},
   "source": [
    "# Calculate dot product and cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "18badf71-d7bc-4829-89b4-cdfe6f050474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot product between vector1 - [1,2,3] and \n",
      " vector2 - [1,2,3] \n",
      " : 14.0\n",
      "dot product between vector1 - [1,2,3] and \n",
      " vector3 - [4,5,6] \n",
      " : 32.0\n",
      "dot product between vector1 - [1,2,3] and \n",
      " vector4 - [-1,-5,-6] \n",
      " : -29.0\n"
     ]
    }
   ],
   "source": [
    "print(f'dot product between vector1 - [1,2,3] and \\n vector2 - [1,2,3] \\n : {dot_product(vector1,vector2)}')\n",
    "print(f'dot product between vector1 - [1,2,3] and \\n vector3 - [4,5,6] \\n : {dot_product(vector1,vector3)}')\n",
    "print(f'dot product between vector1 - [1,2,3] and \\n vector4 - [-1,-5,-6] \\n : {dot_product(vector1,vector4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aeab81-a794-4f46-bce1-3e0aa23353d1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Vector 1 and vector 2 should have the higher value. but dot product is not giving the exact result.\n",
    "\n",
    "lets use `cosine similarity`\n",
    "\n",
    "` we normalize by the magnitude `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d4b36c14-36f5-4ea1-9eaf-604001d97ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity between vector1 - [1,2,3] and \n",
      " vector2 - [1,2,3] \n",
      " : 0.9999999403953552\n",
      "cosine similarity between vector1 - [1,2,3] and \n",
      " vector3 - [4,5,6] \n",
      " : 0.9746317863464355\n",
      "cosine similarity between vector1 - [1,2,3] and \n",
      " vector4 - [-1,-5,-6] \n",
      " : -0.9843241572380066\n"
     ]
    }
   ],
   "source": [
    "print(f'cosine similarity between vector1 - [1,2,3] and \\n vector2 - [1,2,3] \\n : {cosine_similarity(vector1,vector2)}')\n",
    "print(f'cosine similarity between vector1 - [1,2,3] and \\n vector3 - [4,5,6] \\n : {cosine_similarity(vector1,vector3)}')\n",
    "print(f'cosine similarity between vector1 - [1,2,3] and \\n vector4 - [-1,-5,-6] \\n : {cosine_similarity(vector1,vector4)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
